{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# MetaCast: Disease X Demonstration\n",
    "\n",
    "MetaCast has been developed from the codebase used in [Grunnill et al. (2024)](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011018). MetaCast's main feature is broad**CAST**ing epidemiological and ecological subpopulation models over multiple dimensions (axis) to form a **META**population model.\n",
    "\n",
    "This notebook uses a disease X $S E I H R$ (Susceptible - Exposed - Infected - Hospitalised - Recovered) subpopulation model as a motivating example. In this notebook we will model possible scenarios an outbreak of disease X may present:\n",
    "1. Risk-Structured: Single Dimension/Axis disease X model.\n",
    "2. Seeding at X% prevalence: MultinomialSeeder\n",
    "3. A Rapid Pathogen test: Discrete Event simulation within a 2 dimensional/axis disease X model.\n",
    "4. New Vaccine: Multi Dimension/Axis disease X model with flows between some subpopulations.\n",
    "5. New Vaccine's Efficacy is Uncertain: Latin Hypercube Sampling in simulation of a 2 dimensional/axis disease X model.\n",
    "\n",
    "In all of these scenarios we will focus on Peak Hospitilisation and Total Hospitalisations as outputs of the simulated disease X outbreak.\n",
    "\n",
    "## Suggested Reading: Metapopulation and Structured Population Models.\n",
    "\n",
    "**Note** MetaCast has tried to keep to the mathematical notation seen in the first of the following:\n",
    "\n",
    "Keeling, M. J., & Rohani, P. (2008). Metapopulations. In Modeling Infectious Diseases in Humans and Animals (pp. 237–240). Princeton University Press.\n",
    "\n",
    "Keeling, M. J., & Rohani, P. (2008). Age-Structure: Childhood Infections. In Modeling Infectious Diseases in Humans and Animals (pp. 77–92). Pinston University Press.\n",
    "\n",
    "## Suggested Reading: Performing Sensitivity Analyses.\n",
    "\n",
    "Marino, S., Hogue, I. B., Ray, C. J., & Kirschner, D. E. (2008). A methodology for performing global uncertainty and sensitivity analysis in systems biology. In Journal of Theoretical Biology (Vol. 254, Issue 1, pp. 178–196). [https://doi.org/10.1016/j.jtbi.2008.04.011](https://doi.org/10.1016/j.jtbi.2008.04.011), [https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2570191/](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2570191/)\n",
    "\n",
    "## Suggested Reading: Demonstrating a Scenario Analyses that can be Performed using this Package\n",
    "\n",
    "`MetaCast` was developed from the code base that was previously used in:\n",
    "\n",
    "Grunnill, M., Arino, J., McCarthy, Z., Bragazzi, N. L., Coudeville, L., Thommes, E., Amiche, A., Ghasemi, A., Bourouiba, L., Tofighi, M., Asgary, A., Baky-Haskuee, M., & Wu, J. (2024). Modelling Disease Mitigation at Mass Gatherings: A Case Study of COVID-19 at the 2022 FIFA World Cup. In E. H. Lau (Ed.), PLoS Computational Biology: Vol. January (Issue 1, p. e1011018). Public Library of Science. [https://doi.org/10.1371/JOURNAL.PCBI.1011018](https://doi.org/10.1371/JOURNAL.PCBI.1011018)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 1. Risk-Structured: Single Dimension/Axis disease X model.\n",
    "\n",
    "In this section we will be using our model with two groups, one at high risk of hospitalisation and another at a low risk (as shown in the equations below). The $r$ subscript denotes risk group, $p_{r}$ denotes the probability of becoming hospitalised for that risk group and $\\lambda_{r}$ is the force of infection for that risk group. $\\sigma^{-1}$ is the latency period. After $\\gamma^{-1}$ days infectious individuals either recover ($1-p_{r}$) or are hospitalised ($p_{r}$). Hospitalised individuals recover after $\\eta^{-1}$ days.\n",
    "$$\n",
    "    \\frac{\\delta S_{r}}{\\delta t} = -\\lambda_{r} S_{r}\n",
    "$$\n",
    "$$\n",
    "    \\frac{\\delta E_{r}}{\\delta t} = \\lambda_{r} S_{r} - \\sigma E_{r}\n",
    "$$\n",
    "$$\n",
    "    \\frac{\\delta I_{r}}{\\delta t} = \\sigma E_{r} - \\gamma I_{r}\n",
    "$$\n",
    "$$\n",
    "    \\frac{\\delta H_{r}}{\\delta t} = p_{r} \\gamma I_{r} - \\eta H_{r}\n",
    "$$\n",
    "$$\n",
    "    \\frac{\\delta R_{r}}{\\delta t} = (1-p_{r}) \\gamma I_{r} + \\eta H_{r}\n",
    "$$\n",
    "\n",
    "The force of infection ($\\lambda_{r}$), shown below, for subpopulation $i$ is dependent on the number of infecteds in subpopulation $j$, the strength of interaction between subpopulation those subpopulations ($\\rho_{ij}$) and the general transmission term for subpopulation $i$ ($\\beta_{i}$).\n",
    "$$\n",
    "    \\lambda_{i} = \\beta_{i} \\sum_{j} \\rho_{ij} I_j\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 1.1 MetaCaster setup\n",
    "\n",
    "`MetaCast`'s main workhorse is the `MetaCaster` class. This needs to be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from metacast import MetaCaster # Import MetaCast's main class MetaCaster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 1.1.1 Define subpopulation model.\n",
    "\n",
    "The subpop_model function is your subpopulation model (see 1.) that `MetaCaster` will broadcast across the metapopulation generated by your dimensions (see 1.2).\n",
    "The docstring below explains how the required arguments are used by `MetaCaster`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def subpop_model(y, y_deltas, parameters, states_index, subpop_suffix, foi):\n",
    "    \"\"\"\n",
    "    Calculate derivatives of variables in disease X's subpopulation model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : numpy.Array\n",
    "        An array of the state variables at this time point.\n",
    "    y_deltas : numpy.Array\n",
    "        The derivatives of y at this time. MetaCaster gives y_delta as a numpy array of zeros to which this function adds the derivatives to.\n",
    "    parameters : dict {str: Number or callable}\n",
    "        A dictionary of parameter values or callables used to calculate parameter values at this time point.\n",
    "    subpop_suffix : string\n",
    "        This string is of the form '_['coodinate_1,coordinate_2,....']' and is appended to a string denoting parameter specifcally applied to this subpopulation. Alternatively a coordinates argument can be given.\n",
    "    states_index : dict {str:int}\n",
    "        This dictionary is used to look up the indexes on y and y_delta for states is this subpopulation.\n",
    "    foi : float\n",
    "        Force of infection (lambda) experienced be susceptible hosts in this subpopulation. Note the term lambda could not be used as it is used for lambda functions within python. Therefore, the term foi (Force Of Infection) is used.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y_deltas : numpy.Array\n",
    "        Derivatives of variables in disease X's subpopulation model.\n",
    "\n",
    "    \"\"\"\n",
    "    infections = foi * y[states_index['S']]\n",
    "    progression_from_exposed = parameters['sigma'] * y[states_index['E']]\n",
    "    probability_of_hospitalisation = parameters['p' + subpop_suffix] # this is our subpopulation specific parameter\n",
    "    progression_from_infectious = y[states_index['I']]*parameters['gamma']\n",
    "    recovery = progression_from_infectious*(1-probability_of_hospitalisation)\n",
    "    hospitalisation = progression_from_infectious*probability_of_hospitalisation\n",
    "    hospital_recovery = y[states_index['H']]*parameters['eta']\n",
    "\n",
    "\n",
    "    # Updating y_deltas with derivative calculations from this subpopulation.\n",
    "    y_deltas[states_index['S']] += - infections\n",
    "    y_deltas[states_index['E']] += infections - progression_from_exposed\n",
    "    y_deltas[states_index['I']] += progression_from_exposed - progression_from_infectious\n",
    "    y_deltas[states_index['H']] += hospitalisation - hospital_recovery\n",
    "    y_deltas[states_index['R']] += recovery+hospital_recovery\n",
    "    y_deltas[-2] += hospitalisation - hospital_recovery # The last few elements of y_delta can be used for observed states such Total hospital incidence.\n",
    "    y_deltas[-1] += hospitalisation #or Total hospitalisations.\n",
    "\n",
    "    return y_deltas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 1.1.2 Define metapopulation dimensions.\n",
    "\n",
    "In this first example we are assuming structure comes from just the risk of hospitalisation (low and high). As we are dealing with a one dimension axis metapopulation we can provide a set of strings as our dimensions (a list/tuple of unique strings is also acceptable). **Note** if dealing with a multidimensional metapopulation the dimensions would have to be a list/tuple of sets of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "risk_groups = ['low', 'high']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 1.1.3 Intialise MetaCaster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "metapop_model = MetaCaster(dimensions=risk_groups,\n",
    "                           subpop_model=subpop_model,\n",
    "                           states =['S', 'E', 'I', 'H', 'R'], # States of our model\n",
    "                           infected_states= ['E', 'I', 'H'], # Infected states of our model, this is different from infectious states.\n",
    "                           infectious_states=['I'], # Infectious states of our model. These will be involved in force of infection calculations.\n",
    "                           symptomatic_states=['I', 'H'], # List symptomatic states\n",
    "                           observed_states=['H','H_cumulative'], # observed_states is where we name what is being tracked in the last few elements of y_deltas.\n",
    "                           universal_params=['sigma', 'gamma', 'eta'], # These are parameters that are not specific to subpopulations.\n",
    "                           subpop_params=['p'], # These are parameter that are specific to subpopulation, but not those included in transmission (i.e. beta and rho).\n",
    "                           foi_population_focus=None # Determines the population denominator used for calculating force of infection see Keeling & Rohani,(2008, pp. 237–240).\n",
    "                           # If not given or None density dependent transmission is assumed.\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**Note** if you are familiar with python you could alternatively initialise your own subclass of `MetaCaster` with just the dimensions argument. You would need to replace that subclass's subpop_model method and give it the attributes seen in other_model_attributes.\n",
    "\n",
    "# 1.2 Running model\n",
    "## 1.2.1 Setting population\n",
    "\n",
    "For this we will need numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "We need the state_index dictionary for each subpopulation. This gives us our indexes to use on the numpy array defining our initial population $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'S': 0, 'E': 1, 'I': 2, 'H': 3, 'R': 4}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "{'S': 5, 'E': 6, 'I': 7, 'H': 8, 'R': 9}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state_index_dict_high = metapop_model.state_index['high']\n",
    "state_index_dict_low = metapop_model.state_index['low']\n",
    "display(state_index_dict_low, state_index_dict_high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Now we can define $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([8.99999e+05, 0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00,\n       1.00000e+05, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n       0.00000e+00, 0.00000e+00])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1e6\n",
    "proportion_high_risk = 0.1\n",
    "low_risk_population = N*(1-proportion_high_risk)\n",
    "high_risk_population = N*proportion_high_risk\n",
    "y = np.zeros(metapop_model.total_states) # Use the total number of states in our model to define y.\n",
    "y[state_index_dict_low['S']] = low_risk_population-1\n",
    "y[state_index_dict_low['I']] = 1\n",
    "y[state_index_dict_high['S']] = high_risk_population\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 1.2.2 Setting up parameters\n",
    "\n",
    "For this we will need to know the names of all of our parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['beta_[high]',\n 'beta_[low]',\n 'eta',\n 'gamma',\n 'p_[high]',\n 'p_[low]',\n 'rho_[high]_[high]',\n 'rho_[high]_[low]',\n 'rho_[low]_[high]',\n 'rho_[low]_[low]',\n 'sigma']"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metapop_model.parameter_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Now we can define our parameters in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'eta': 0.2,\n 'gamma': 0.14285714285714285,\n 'sigma': 0.3333333333333333,\n 'p_[high]': 0.3,\n 'p_[low]': 0.01,\n 'beta_[low]': 2.857142857142857e-07,\n 'beta_[high]': 2.857142857142857e-07,\n 'rho_[low]_[low]': 1,\n 'rho_[low]_[high]': 1,\n 'rho_[high]_[low]': 1,\n 'rho_[high]_[high]': 1}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_subpop_parameters = {'eta': 1/5, 'gamma': 1/7,  'sigma': 1/3}\n",
    "p_high = 0.3\n",
    "p_low = 0.01\n",
    "hospitalisation_probs = {'p_[high]': p_high, 'p_[low]': p_low}\n",
    "beta = (2/7)/N\n",
    "beta_parameters = {'beta'+ subpop_suffix: beta for subpop_suffix in metapop_model.subpop_suffixes}\n",
    "rho = 1\n",
    "interaction_parameters = {'rho'+ subpop_suffix_i+subpop_suffix_j: rho\n",
    "                          for subpop_suffix_i in metapop_model.subpop_suffixes\n",
    "                          for subpop_suffix_j in metapop_model.subpop_suffixes}\n",
    "parameters = non_subpop_parameters | hospitalisation_probs | beta_parameters | interaction_parameters\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "We can now use our parameter dictionary to assign our parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'beta_[high]': 2.857142857142857e-07,\n 'beta_[low]': 2.857142857142857e-07,\n 'eta': 0.2,\n 'gamma': 0.14285714285714285,\n 'p_[high]': 0.3,\n 'p_[low]': 0.01,\n 'rho_[high]_[high]': 1,\n 'rho_[high]_[low]': 1,\n 'rho_[low]_[high]': 1,\n 'rho_[low]_[low]': 1,\n 'sigma': 0.3333333333333333}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metapop_model.parameters = parameters\n",
    "metapop_model.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 1.2.3 Run metapopulation model\n",
    "\n",
    "Before running our model we need to define our timeframe $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n       85, 86, 87, 88, 89, 90])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set time\n",
    "end_day = 90\n",
    "time_step = 1\n",
    "t = np.arange(0, end_day+time_step, time_step)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Now we can use $y$ and $t$ with the `integrate` method to simulate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m results_1 \u001B[38;5;241m=\u001B[39m \u001B[43mmetapop_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mintegrate\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m results_1\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\GitHub\\MetaCast\\src\\metacast\\metacaster.py:676\u001B[0m, in \u001B[0;36mMetaCaster.integrate\u001B[1;34m(self, x0, t, full_output, **kwargs_to_pass_to_odeint)\u001B[0m\n\u001B[0;32m    663\u001B[0m args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mvalues())\n\u001B[0;32m    664\u001B[0m \u001B[38;5;66;03m# The if else statement below is for use with DOK matrix version of the Jacobian see sileneced section below.\u001B[39;00m\n\u001B[0;32m    665\u001B[0m \u001B[38;5;66;03m# if self.dok_jacobian is None: # May or may not of defined the models Jacobian\u001B[39;00m\n\u001B[0;32m    666\u001B[0m \u001B[38;5;66;03m#     solution, output = scipy.integrate.odeint(self.ode,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    674\u001B[0m \u001B[38;5;66;03m#                                               full_output=True,\u001B[39;00m\n\u001B[0;32m    675\u001B[0m \u001B[38;5;66;03m#                                               **kwargs_to_pass_to_odeint)\u001B[39;00m\n\u001B[1;32m--> 676\u001B[0m solution, output \u001B[38;5;241m=\u001B[39m \u001B[43mscipy\u001B[49m\u001B[38;5;241m.\u001B[39mintegrate\u001B[38;5;241m.\u001B[39modeint(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mode,\n\u001B[0;32m    677\u001B[0m                                           x0, t, args\u001B[38;5;241m=\u001B[39margs,\n\u001B[0;32m    678\u001B[0m                                           full_output\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    679\u001B[0m                                           \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs_to_pass_to_odeint)\n\u001B[0;32m    680\u001B[0m solution \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults_array_to_df(solution, t)\n\u001B[0;32m    681\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m full_output:\n\u001B[0;32m    682\u001B[0m     \u001B[38;5;66;03m# have both\u001B[39;00m\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\GitHub\\MetaCast\\src\\metacast\\metacaster.py:676\u001B[0m, in \u001B[0;36mMetaCaster.integrate\u001B[1;34m(self, x0, t, full_output, **kwargs_to_pass_to_odeint)\u001B[0m\n\u001B[0;32m    663\u001B[0m args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mvalues())\n\u001B[0;32m    664\u001B[0m \u001B[38;5;66;03m# The if else statement below is for use with DOK matrix version of the Jacobian see sileneced section below.\u001B[39;00m\n\u001B[0;32m    665\u001B[0m \u001B[38;5;66;03m# if self.dok_jacobian is None: # May or may not of defined the models Jacobian\u001B[39;00m\n\u001B[0;32m    666\u001B[0m \u001B[38;5;66;03m#     solution, output = scipy.integrate.odeint(self.ode,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    674\u001B[0m \u001B[38;5;66;03m#                                               full_output=True,\u001B[39;00m\n\u001B[0;32m    675\u001B[0m \u001B[38;5;66;03m#                                               **kwargs_to_pass_to_odeint)\u001B[39;00m\n\u001B[1;32m--> 676\u001B[0m solution, output \u001B[38;5;241m=\u001B[39m \u001B[43mscipy\u001B[49m\u001B[38;5;241m.\u001B[39mintegrate\u001B[38;5;241m.\u001B[39modeint(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mode,\n\u001B[0;32m    677\u001B[0m                                           x0, t, args\u001B[38;5;241m=\u001B[39margs,\n\u001B[0;32m    678\u001B[0m                                           full_output\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    679\u001B[0m                                           \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs_to_pass_to_odeint)\n\u001B[0;32m    680\u001B[0m solution \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults_array_to_df(solution, t)\n\u001B[0;32m    681\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m full_output:\n\u001B[0;32m    682\u001B[0m     \u001B[38;5;66;03m# have both\u001B[39;00m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:929\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:920\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:317\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2022.2.4\\plugins\\python\\helpers\\pydev\\pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2022.2.4\\plugins\\python\\helpers\\pydev\\pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1175\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "results_1 = metapop_model.integrate(y,t)\n",
    "results_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 1.2.4 Plotting hospitalisations\n",
    "\n",
    "Let's plot some of the results of our simulation. For this we will need seaborn and pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "The function below unstacks our reslults so they can be used by seaborn and then plots the number or hospitalisation ($H$) in our subpopulations and observed_states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def unstack_results_and_plot_hospitalised(results):\n",
    "    results_unstacked = results.unstack()\n",
    "    results_unstacked = results_unstacked.reset_index()\n",
    "    results_unstacked.columns = ['Subpopulation', 'State','t', 'value']\n",
    "    hospitalised_results = results_unstacked[results_unstacked['State']=='H']\n",
    "    sns.lineplot(hospitalised_results,x='t',y='value',hue='Subpopulation')\n",
    "    return results_unstacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "results_1_unstacked = unstack_results_and_plot_hospitalised(results_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "We can find out the peak hospitilisations and total_hospitalisations using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "hospitalised_records = [\n",
    "    {'Scenario': 'Single infection at start',\n",
    "     'Total hospitalisations': results_1.loc[90,('observed_states','H_cumulative')],\n",
    "     'Peak hospitalisations': max(results_1.loc[:,('observed_states','H')]),\n",
    "     }\n",
    "]\n",
    "pd.DataFrame.from_records(hospitalised_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 2. Seeding at X proportion prevalence: MultinomialSeeder\n",
    "\n",
    "MetaCast comes with a `MultinomialSeeder` for seeding infected population randomly drawing probabilities based time spent in compartments. In this example we will use `MultinomialSeeder` to seed our population with a chosen prevalence before running the model defined in the previous section.\n",
    "\n",
    "## 2.1 Set up Seeders\n",
    "\n",
    "For this we need to import metacast `MultinomialSeeder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from metacast import MultnomialSeeder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Then we need to define a seeding information dictionary for `MultinomialSeeder`. This seeding information is a nested dictionary. The first level keys are the possible branches of your infecteds (infection course). The lowest level keys are the states with values being the rate at which people leave that state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "seeding_info = {'unhospitalised': {'E': 'sigma','I':'gamma'},\n",
    "                'hospitalised': {'E': 'sigma','I':'gamma', 'H':'eta'},\n",
    "                }\n",
    "seeder = MultnomialSeeder(seeding_info)\n",
    "seeder.set_seed(42) # This class uses random number generation (rng) use set_seed function to set rng seed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 2.2 Setup Populations with seeder\n",
    "\n",
    "We can now random draws for our low and high risk population for a given prevalence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "prevelance = 0.01\n",
    "low_risk_total_infected = low_risk_population*prevelance\n",
    "low_risk_infected = seeder.seed_infections(n=low_risk_total_infected,\n",
    "                                           branch_probability={'unhospitalised': 1- parameters['p_[low]'] ,'hospitalised': parameters['p_[low]']},\n",
    "                                           parameters=parameters)\n",
    "low_risk_infected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "high_risk_total_infected = high_risk_population*prevelance\n",
    "high_risk_infected = seeder.seed_infections(n=high_risk_total_infected,\n",
    "                                            branch_probability={'unhospitalised': 1- parameters['p_[high]'] ,'hospitalised': parameters['p_[high]']},\n",
    "                                            parameters=parameters)\n",
    "high_risk_infected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Now we can use those draws in setting up our high and low risk populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "y =np.zeros(metapop_model.total_states)\n",
    "low_risk_state_pops = {'S':low_risk_population*(1-prevelance), **low_risk_infected}\n",
    "for state, index in state_index_dict_low.items():\n",
    "    if state in low_risk_state_pops:\n",
    "        y[index] = low_risk_state_pops[state]\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "high_risk_state_pops = {'S':high_risk_population*(1-prevelance), **high_risk_infected}\n",
    "for state, index in state_index_dict_high.items():\n",
    "    if state in high_risk_state_pops:\n",
    "        y[index] = high_risk_state_pops[state]\n",
    "\n",
    "y[-2] += low_risk_state_pops['H'] + high_risk_state_pops['H']\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 2.3 Run metapopulation model\n",
    "\n",
    "The code below runs the model with our new starting population $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "results_seeded = metapop_model.integrate(y,t)\n",
    "results_seeded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 2.4 Plotting hospitalisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "unstack_results_and_plot_hospitalised(results_seeded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Let's compare with Total hospitalised and Peak Hospitalised from previous scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "hospitalised_records.append(\n",
    "    {'Scenario': 'Starting prevalence of ' + str(prevelance),\n",
    "     'Total hospitalisations': results_seeded.loc[90,('observed_states','H_cumulative')],\n",
    "     'Peak hospitalisations': max(results_seeded.loc[:,('observed_states','H')]),\n",
    "     }\n",
    ")\n",
    "pd.DataFrame.from_records(hospitalised_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 3. A Rapid Pathogen test: Discrete Event simulation within a 2 dimensional/axis disease X model.\n",
    "\n",
    "In this scenario we are going to assume that a new affordable rapid test for disease X has become available. Positive tests result in those in states $E$ or $I$ being moved to an isolating test positive population. For this scenario we will need to:\n",
    " * Extend our metapopulation dimensions for those who tested postive and negative.\n",
    "  * Set up a MetaCast's event que with the new rapid pathogen test as a discrete event.\n",
    "\n",
    "The equation for the model in this scenario very similar to the previous scenario's. The subscript $q$ has been added to denote those isolating (in quarantine) as the result of a positive test for disease X.\n",
    "$$\n",
    "    \\frac{\\delta S_{r,q}}{\\delta t} = -\\lambda_{r,q} S_{r,q}\n",
    "$$\n",
    "$$\n",
    "    \\frac{\\delta E_{r,q}}{\\delta t} = \\lambda_{r,q} S_{r,q} - \\sigma E_{r,q}\n",
    "$$\n",
    "$$\n",
    "    \\frac{\\delta I_{r,q}}{\\delta t} = \\sigma E_{r,q} - \\gamma I_{r,q}\n",
    "$$\n",
    "$$\n",
    "    \\frac{\\delta H_{r,q}}{\\delta t} = p_{r,q} \\gamma I_{r,q} - \\eta H_{r,q}\n",
    "$$\n",
    "$$\n",
    "    \\frac{\\delta R_{r,q}}{\\delta t} = (1-p_{r,q}) \\gamma I_{r,q} + \\eta H_{r,q}\n",
    "$$\n",
    "$$\n",
    "    \\lambda_{i} = \\beta_{i} \\sum_{j} \\rho_{ij} I_j\n",
    "$$\n",
    "\n",
    "\n",
    "## 3.1 Change Population Structure\n",
    "\n",
    "Lets start be changing the dimensions of our metapopulation by adding a new dimension for those who tested positive and those who tested negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "isolation_groups = ['negative','positive']\n",
    "rapid_pathogen_test_dimensions = [risk_groups,isolation_groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "metapop_model.dimensions = rapid_pathogen_test_dimensions\n",
    "metapop_model.dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 3.2 Set Population\n",
    "\n",
    "We need to change our starting population as a result of the change in our metapopulation model's dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "y =np.zeros(metapop_model.total_states)\n",
    "low_risk_state_pops = {'S':low_risk_population*(1-prevelance), **low_risk_infected}\n",
    "for state, index in metapop_model.state_index[('low', 'negative')].items():\n",
    "    if state in low_risk_state_pops:\n",
    "        y[index] = low_risk_state_pops[state]\n",
    "high_risk_state_pops = {'S':high_risk_population*(1-prevelance), **high_risk_infected}\n",
    "for state, index in metapop_model.state_index[('high', 'negative')].items():\n",
    "    if state in high_risk_state_pops:\n",
    "        y[index] = high_risk_state_pops[state]\n",
    "\n",
    "y[-2] += low_risk_state_pops['H'] + high_risk_state_pops['H']\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 3.3 Set parameters\n",
    "\n",
    "We also need to change our parameter values as a result of the change in our metapopulation model's dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "metapop_model.parameter_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "beta_parameters = {'beta' + subpop_suffix: beta for subpop_suffix in metapop_model.subpop_suffixes}\n",
    "isolation_hospitalisation_probs = {\n",
    "    **{'p_[high,'+ isolation_group +']': hospitalisation_probs['p_[high]'] for isolation_group in isolation_groups},\n",
    "    **{'p_[low,'+ isolation_group +']': hospitalisation_probs['p_[low]'] for isolation_group in isolation_groups}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "These new parameters need to account of the effect of isolation on the strength of transmission between populations $\\rho_{ij}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "transmission_reduction_from_isolation = 0.6\n",
    "interaction_parameters = {\n",
    "    **{'rho'+ subpop_suffix_i+'_['+risk_group +',negative]': rho\n",
    "       for subpop_suffix_i in metapop_model.subpop_suffixes\n",
    "       for risk_group in risk_groups},\n",
    "    **{'rho'+ subpop_suffix_i+'_['+risk_group +',positive]': rho*(1-transmission_reduction_from_isolation)\n",
    "       for subpop_suffix_i in metapop_model.subpop_suffixes\n",
    "       for risk_group in risk_groups}\n",
    "}\n",
    "interaction_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "parameters = non_subpop_parameters | isolation_hospitalisation_probs | beta_parameters | interaction_parameters\n",
    "metapop_model.parameters = parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 3.4 Set up Event Que\n",
    "\n",
    "First we need to import the `EventQueue` and `TransferEvent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from metacast.event_handling import EventQueue, TransferEvent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "For those that would isolate if they comply with isolation order on a positive test we need the following:\n",
    " * The indexes of their current compartment (a from_index).\n",
    "  * The index of the corresponding isolation compartment they would move to (a to_index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from_index = [index\n",
    "              for risk_group in risk_groups\n",
    "              for state, index in metapop_model.state_index[(risk_group,'negative')].items()\n",
    "              if state in ['E','I']]\n",
    "to_index = [index\n",
    "            for risk_group in risk_groups\n",
    "            for state, index in metapop_model.state_index[(risk_group,'positive')].items()\n",
    "            if state in ['E','I']]\n",
    "display({'from index': from_index,'to index': to_index})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "With our from_index and to_index we can set up a `TransferEvent` as our 'Rapid Pathogen Test'. The TransferEvent will also need:\n",
    " * A range of time at which to be triggered.\n",
    "  * The proportion of population to move between the compartments in our from_index and to_index.\n",
    "* A name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "test_every_x_days = 7\n",
    "complaince = 0.8\n",
    "test_sensitivity = 0.6\n",
    "rapid_pathogen_test_event = TransferEvent(name='Rapid Pathogen Test',\n",
    "                                          times= range(0,end_day+time_step,test_every_x_days),\n",
    "                                          proportion= test_sensitivity*complaince,\n",
    "                                          from_index= from_index,\n",
    "                                          to_index= to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "With our 'Rapid Pathogen Test' set up we can set up our event que."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "testing_eventqueue = EventQueue(rapid_pathogen_test_event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**Note** you can set up the `EventQueue` with multiple event using a list. There are also more event types available than just the TransferEvent see [https://metacast.readthedocs.io/en/latest/autoapi/metacast/event_handling/events/index.html](https://metacast.readthedocs.io/en/latest/autoapi/metacast/event_handling/events/index.html).\n",
    "\n",
    "## 3.5 Run simulations with Events\n",
    "\n",
    "In order to run simulations using the `EventQueue` we need to give the `run_sumulation` method the following arguments:\n",
    "* model_object : The object used to define and simulate model.\n",
    "* run_attribute : The name of model_objects method that simulates model. Must return either a numpy array of pandas.DataFrame.\n",
    "* y0 : A numpy.array storing the intial values of state varibles.\n",
    "* end_time : The stop time of simulations.\n",
    "* parameters_attribute : The name of the attribute of model_object that sets parameters (must accept dictionary where keys are strings and values are floats/ints).\n",
    "* parameters : A dictionary {str : floats/ints} defining the model parameters.\n",
    "\n",
    "Start_time and simulation_step (simulation time step) are optional. If not given the will be set at default values (start_time=0 and simulation_step=1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "results_rapid_test, transfer_df = testing_eventqueue.run_simulation(model_object=metapop_model,\n",
    "                                                                    run_attribute='integrate',\n",
    "                                                                    parameters=parameters,\n",
    "                                                                    parameters_attribute='parameters',\n",
    "                                                                    y0=y,\n",
    "                                                                    end_time=end_day,\n",
    "                                                                    start_time=0,\n",
    "                                                                    simulation_step=time_step)\n",
    "results_rapid_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "As well as a pandas.DataFrame giving results of the simulation the `run_simulation` method return a transfer_df DataFrame outlineing the details of events that transferred populations between compartments. This can be handy in debugging or scenario analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "transfer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 3.6 Plotting hospitalisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "results_rapid_test_unstacked = unstack_results_and_plot_hospitalised(results_rapid_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Let's compare with Total hospitalised and Peak Hospitalised from previous scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "hospitalised_records.append(\n",
    "    {'Scenario': 'Tests every ' + str(test_every_x_days) + ' day resulting in ' + str(complaince*test_sensitivity) + ' in isolation ('+\n",
    "                 str(1-transmission_reduction_from_isolation) + ' transmission).',\n",
    "     'Total hospitalisations': results_rapid_test.loc[90,('observed_states','H_cumulative')],\n",
    "     'Peak hospitalisations': max(results_rapid_test.loc[:,('observed_states','H')])\n",
    "     }\n",
    ")\n",
    "pd.DataFrame.from_records(hospitalised_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 3.6 Comparing with Rapid test event turned to null (do nothing) event.\n",
    "\n",
    "In testing the code `MetaCast` was developed from [(Grunnill et al. 2024)](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011018) we found that the precision of Scipy's `odeint` could vary when running many events in an event queue. Scipy `odeint` being the underlying function for `MetaCaster`'s integrate function. Therefore, we added an easy way to make events do nothing, a `make_event_a_nullevent` method, to check for differences due to odeint differing precision.\n",
    "\n",
    "Let check that such differences `odeint`'s precision have not crept. To do this we will compare eventque simulation with `rapid_pathogen_test_event` set to do nothing with simulations from section 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "rapid_pathogen_test_event.make_event_a_nullevent()\n",
    "results_rapid_test_null, transfer_df = testing_eventqueue.run_simulation(model_object=metapop_model,\n",
    "                                                                         run_attribute='integrate',\n",
    "                                                                         parameters=parameters,\n",
    "                                                                         parameters_attribute='parameters',\n",
    "                                                                         y0=y,\n",
    "                                                                         end_time=end_day,\n",
    "                                                                         start_time=0,\n",
    "                                                                         simulation_step=time_step)\n",
    "results_rapid_test_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "transfer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "results_rapid_test_null_unstacked = unstack_results_and_plot_hospitalised(results_rapid_test_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Let's compare with Total hospitalised and Peak Hospitalised from previous scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "hospitalised_records.append(\n",
    "    {'Scenario': 'Do nothing event.',\n",
    "     'Total hospitalisations': results_rapid_test_null.loc[90,('observed_states','H_cumulative')],\n",
    "     'Peak hospitalisations': max(results_rapid_test_null.loc[:,('observed_states','H')])\n",
    "     }\n",
    ")\n",
    "pd.DataFrame.from_records(hospitalised_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "As we can see there is no differences caused by a change in odeint's precision. If there were we would have to compare our 'Tests every 7 day resulting in 0.48 in isolation (0.4 transmission)' scenario to the 'Do nothing event'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 4. New Vaccine: Multi Dimension/Axis disease X model with flows between some subpopulations.\n",
    "\n",
    "In this scenario we will be looking at the deployment of a new vaccine that has become available for disease X. This new vaccine is not completely transmission blocking, but does at least provide some protection against hospitalisations in breakthrough infections. We will therefore be replacing the second dimension in our previous model from 'negative' and 'positive' to 'unvaccinated', 'vaccination_lag' and 'vaccinated'. We will also setup flows of population between these dimensions 'unvaccinated'->'vaccination_lag'->'vaccinated'.\n",
    "\n",
    "The equation for the model in this scenario have changed a bit from the previous scenario's. The subscript $v$ replaces $q$ to denote 'unvaccinated', 'vaccination_lag' and 'vaccinated' groups.\n",
    "\n",
    "$$\n",
    "    \\frac{\\delta S_{r,v}}{\\delta t} = \\nu_{v-1} S_{r,v-1} - \\lambda_{r,v} S_{r,v} - \\nu_{v} S_{r,v}\n",
    "$$\n",
    "$$\n",
    "    \\frac{\\delta E_{r,v}}{\\delta t} = \\nu_{v-1} E_{r,v-1} + \\lambda_{r,v} S_{r,v} - \\sigma E_{r,v} - \\nu_{v} E_{r,v}\n",
    "$$\n",
    "$$\n",
    "    \\frac{\\delta I_{r,v}}{\\delta t} = \\nu_{v-1} I_{r,v-1} + \\sigma E_{r,v} - \\gamma I_{r,v} - \\nu_{v} I_{r,v}\n",
    "$$\n",
    "$$\n",
    "    \\frac{\\delta H_{r,v}}{\\delta t} = \\nu_{v-1} H_{r,v-1} + p_{r,v} \\gamma I_{r,v} - \\eta H_{r,v} - \\nu_{v} H_{r,v}\n",
    "$$\n",
    "$$\n",
    "    \\frac{\\delta R_{r,v}}{\\delta t} = \\nu_{v-1} R_{r,v-1} + (1-p_{r,v}) \\gamma I_{r,v} + \\eta H_{r,v} - \\nu_{v} R_{r,v}\n",
    "$$\n",
    "$$\n",
    "    \\lambda_{i} = \\beta_{i} \\sum_{j} \\rho_{ij} I_j\n",
    "$$\n",
    "\n",
    "For our vaccinated populations $\\beta_{r,v=vaccinated}=\\beta(1-l_v)$ and $p_{r,v=vaccinated}=p_{r}(1-h_v)$. Were $l_v$ is vaccine's effectiveness in decreasing susceptibility and $h_v$ is the vaccines effectiveness in preventing hospitalizing infections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 4.1 Set metapopulation dimensions using a list of subpopulation transfer dictionaries.\n",
    "\n",
    "With flows of population (unvaccinated'->'vaccination_lag'->'vaccinated') we need to define our metapopulation model dimensions differently than in previous scenarios. This time we will define dimensions using a list transfer dictionaries. These transfer dictionaries outline the flow between one subpopulation and another. Each transfer dictionary should contain:\n",
    "\n",
    "* from_coordinates:  Subpopulation coordinates from which hosts are leaving. All of these entries should be of the same length.\n",
    "* to_coordinates:  Subpopulation coordinates from which hosts are leaving. All of these entries should be of the same length and the same length as the from_coordinates entries.\n",
    "* states: Host states which will transition between subpopulations. Single entry of 'all' value means all the available model states transition between subpopulations. Alternatively a list of specific states can be given.\n",
    "* parameter : Name given to parameter that is responsible for flow of hosts transferring between subpopulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "vaccination_groups = ['unvaccinated','vaccination_lag' 'vaccinated']\n",
    "vaccination_transfers = [{'from_coordinates': (risk_group,'unvaccinated'),\n",
    "                          'to_coordinates': (risk_group,'vaccination_lag'),\n",
    "                          'states': 'all', 'parameter': 'nu_unvaccinated'}\n",
    "                         for risk_group in risk_groups]\n",
    "vacination_lag_transfers = [{'from_coordinates': (risk_group,'vaccination_lag'),\n",
    "                             'to_coordinates': (risk_group,'vaccinated'),\n",
    "                             'states': 'all', 'parameter': 'nu_vaccination_lag'}\n",
    "                            for risk_group in risk_groups]\n",
    "\n",
    "vaccination_dimensions = vaccination_transfers + vacination_lag_transfers\n",
    "vaccination_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "metapop_model.dimensions = vaccination_dimensions\n",
    "metapop_model.dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 4.2 Set population\n",
    "\n",
    "We need to change our starting population as a result of the change in our metapopulation model’s dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "metapop_model.total_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "y = np.zeros(metapop_model.total_states)\n",
    "\n",
    "for state, index in metapop_model.state_index[('high','unvaccinated')].items():\n",
    "    if state in high_risk_state_pops:\n",
    "        y[index] = high_risk_state_pops[state]\n",
    "\n",
    "for state, index in metapop_model.state_index[('low','unvaccinated')].items():\n",
    "    if state in low_risk_state_pops:\n",
    "        y[index] =low_risk_state_pops[state]\n",
    "\n",
    "y[-2] += low_risk_state_pops['H'] + high_risk_state_pops['H']\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 4.3 Set parameters\n",
    "\n",
    "We also need to change our parameter values as a result of the change in our metapopulation model's dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "metapop_model.parameter_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "This time around we are going to setup a function for setting up the parameters as we will be using the same metapopulation model in the next exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def vaccination_parameters_setup(nu_unvaccinated,\n",
    "                                 nu_vaccination_lag,\n",
    "                                 l_v,\n",
    "                                 h_v,\n",
    "                                 other_parameters,\n",
    "                                 metapop_model):\n",
    "    parameters = {key: value for key, value in other_parameters.items() if key in metapop_model.parameter_names}\n",
    "    parameters.update({'nu_unvaccinated': nu_unvaccinated,\n",
    "                       'nu_vaccination_lag': nu_vaccination_lag})\n",
    "\n",
    "    beta = other_parameters['beta']\n",
    "    parameters.update({'beta_[high,unvaccinated]': beta,\n",
    "                       'beta_[high,vaccinated]': beta*(1-l_v),\n",
    "                       'beta_[high,vaccination_lag]': beta,\n",
    "                       'beta_[low,unvaccinated]': beta,\n",
    "                       'beta_[low,vaccinated]': beta*(1-l_v),\n",
    "                       'beta_[low,vaccination_lag]': beta})\n",
    "\n",
    "    if h_v < l_v:\n",
    "        raise ValueError('h_v must be greater than or equal to l_v. ' +\n",
    "                         'Otherwise vaccine reduced severity given reduced susceptibility is negative.')\n",
    "\n",
    "    vaccine_reduced_severity_given_reduced_susceptibility = 1-((1-h_v)/(1-l_v))\n",
    "    p_high = other_parameters['p_[high]']\n",
    "    p_low = other_parameters['p_[low]']\n",
    "    parameters.update({'p_[high,unvaccinated]': p_high,\n",
    "                       'p_[high,vaccinated]': p_high*(1-vaccine_reduced_severity_given_reduced_susceptibility),\n",
    "                       'p_[high,vaccination_lag]': p_high,\n",
    "                       'p_[low,unvaccinated]': p_low,\n",
    "                       'p_[low,vaccinated]': p_low*(1-vaccine_reduced_severity_given_reduced_susceptibility),\n",
    "                       'p_[low,vaccination_lag]': p_low})\n",
    "    rho = other_parameters['rho']\n",
    "    parameters.update({'rho'+ subpop_suffix_i+subpop_suffix_j: rho\n",
    "                       for subpop_suffix_i in metapop_model.subpop_suffixes\n",
    "                       for subpop_suffix_j in metapop_model.subpop_suffixes})\n",
    "    return parameters\n",
    "\n",
    "def prob_over_many_days_to_prob_on_a_day(prob, many_days):\n",
    "    return 1-(1-prob)**(1/many_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "v_day = end_day\n",
    "prob_vaccinated_by_v_day = 0.7\n",
    "prob_vaccinated_per_day = prob_over_many_days_to_prob_on_a_day(prob_vaccinated_by_v_day ,v_day)\n",
    "vaccination_lag = 1/14\n",
    "vaccine_reduced_susceptibility = 0.4\n",
    "vaccine_reduced_severity = 0.8\n",
    "other_parameters = {'beta':beta, 'rho': rho, **non_subpop_parameters, **hospitalisation_probs}\n",
    "parameters = vaccination_parameters_setup(nu_unvaccinated=prob_vaccinated_per_day*complaince,\n",
    "                                          nu_vaccination_lag=vaccination_lag,\n",
    "                                          l_v=vaccine_reduced_susceptibility,\n",
    "                                          h_v=vaccine_reduced_severity,\n",
    "                                          other_parameters=other_parameters,\n",
    "                                          metapop_model=metapop_model)\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "metapop_model.parameters = parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 4.4 Run metapopulation model\n",
    "\n",
    "Lets run our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_deltas = metapop_model.subpop_transfer(y=y,\n",
    "                                         y_deltas = np.zeros(metapop_model.total_states),\n",
    "                                         t=0,\n",
    "                                         from_coordinates=('high','unvaccinated'),\n",
    "                                         parameters=parameters)\n",
    "\n",
    "y_deltas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from_coordinates_dict = metapop_model.state_index[('high','unvaccinated')]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_vaccination = metapop_model.integrate(y,t)\n",
    "results_vaccination"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 4.5 Plotting hospitalisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "results_vaccination_unstacked = unstack_results_and_plot_hospitalised(results_vaccination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Let's compare with Total hospitalised and Peak Hospitalised from previous scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "hospitalised_records.append(\n",
    "    {'Scenario': 'Vaccinating ' + str(prob_vaccinated_by_v_day) + ' population by day '+ str(v_day),\n",
    "     'Total hospitalisations': results_vaccination.loc[90,('observed_states','H_cumulative')],\n",
    "     'Peak hospitalisations': max(results_vaccination.loc[:,('observed_states','H')])\n",
    "     }\n",
    ")\n",
    "hospitalised_results_df = pd.DataFrame.from_records(hospitalised_records)\n",
    "hospitalised_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 5. New Vaccine's Efficacy is Uncertain: Latin Hypercube Sampling in simulation of a 2 dimensional disease X model.\n",
    "\n",
    "Some uncertainties have come about in the new vaccine for disease X, both in terms of efficacy and delivery. Therefore, in this next exercise we will running a sensitivity analyses of the metapopulation model from the previous scenario using Latin Hypercube Sampling. For a description of Latin Hypercube Sampling (LHS) and Partial Rank Correlation Coefficients I suggest you read [Marino et, al. (2008)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2570191/).\n",
    "\n",
    "For generating an LH sample, running simulations for all of the parameter sets in the LH sample we will need to import MetaCast's lhs_prcc function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from metacast.sensitivity_analyses import lhs_prcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 5.1 Setup a function for running the metapopulation model.\n",
    "\n",
    "lhs_prcc in tangent with a user defined function that sets up the model and runs a sampled parameter set. Key features of this user defined function are:\n",
    "* The first argument of this function must be for a dictionary of the sampled parameters.\n",
    "* The returned object must be a dictionary combining the first argument of input parameters with the results you wished to see from the simulation.\n",
    "\n",
    "**Note** we will see later that lhs_prcc can pass other key word arguments (kwargs) to this user defined function.\n",
    "\n",
    "Lets create such a function for running our vaccination model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def vaccination_lhs_sim(sample, # First argument must be for a dictionary of the sampled parameters\n",
    "                        t,\n",
    "                        y0,\n",
    "                        fixed_parameter,\n",
    "                        metapop_model):\n",
    "    parameters = vaccination_parameters_setup(**sample, other_parameters=fixed_parameter,\n",
    "                                              metapop_model=metapop_model)\n",
    "    metapop_model.parameters = parameters\n",
    "    results = metapop_model.integrate(y0, t)\n",
    "    focused_results = {'Total hospitalisations': results.loc[90, ('observed_states', 'H_cumulative')],\n",
    "                       'Peak hospitalisations': max(results.loc[:, ('observed_states', 'H')])}\n",
    "    results_and_sample = sample | focused_results #\n",
    "    return results_and_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 5.2 Setup parameter ranges to sample from.\n",
    "\n",
    "In order to generate a LH sample `lhs_prcc` requires a pandas.DataFrame outlining the bombardiers of LHS (our parameter certainties). **Note** currently metacast only support latin hypercube sampling with uniform distributions. Key features of this DataFrame:\n",
    "* Must contain fields 'Lower Bound' and 'Upper Bound'.\n",
    "* The name of the parameters is assumed to be in the index of the DataFrame.\n",
    "\n",
    "The code below creates such a DataFrame outlining certainties surrounding disease X's vaccination parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "parameter_samples_records = [\n",
    "    {'parameter': 'nu_unvaccinated',\n",
    "     'Lower Bound': prob_over_many_days_to_prob_on_a_day(0.5, v_day),\n",
    "     'Upper Bound': prob_over_many_days_to_prob_on_a_day(0.95, v_day)}, # Rate of vaccinations.\n",
    "\n",
    "    {'parameter': 'nu_vaccination_lag', 'Lower Bound': 1/28, 'Upper Bound': 1/7}, # Lag between vaccination and vaccination being effective.\n",
    "    {'parameter': 'l_v', 'Lower Bound': 0.3, 'Upper Bound': 0.6}, # Reduction in susceptibility to disease X after vaccination.\n",
    "    {'parameter': 'h_v', 'Lower Bound': 0.7, 'Upper Bound': 0.95} # Reduction in hospitalisation with disease X after vaccination.\n",
    "]\n",
    "parameter_samples_df = pd.DataFrame.from_records(parameter_samples_records)\n",
    "parameter_samples_df.set_index('parameter',inplace=True) # The parameters must be set as the index of the dataframe.\n",
    "parameter_samples_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##  5.3 Run simulations with LHS\n",
    "\n",
    " Let's test run `lhs_prcc` with a small sample size. As well as the DataFrame outlineing the sampling of parameters and our user defined function for running our model, `lhs_prcc` requires the number of samples generated in the LHS. All other arguments in the code cell below are passed to the function for running our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "results_and_sample_df, prccs = lhs_prcc(parameters_df=parameter_samples_df,\n",
    "                                        sample_size=10,\n",
    "                                        model_run_method=vaccination_lhs_sim,\n",
    "                                        metapop_model=metapop_model,\n",
    "                                        t=t,\n",
    "                                        y0=y,\n",
    "                                        fixed_parameter=other_parameters)\n",
    "results_and_sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "As well as a dataframe of results and sampled parameters `lhs_prcc` performs analyses the ranked correlation between parameters and results. This form of rank correlation coefficent adjusts for the effect of other paramters [(Marino et, al. 2008)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2570191/). The results partial rank correlation coefficient analyses are pictured below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "prccs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Our initial sample size is quite small. We may need to run a much larger sample size. To do so in serially would take a long time. Luckily `lhs_prcc` can take a `dask.distributed.Client` for running simulations in parallel.\n",
    "\n",
    "##  5.4 Run simulations with LHS in parallel\n",
    "\n",
    "First we will need to know the number of cores on the macine we are using. It is best practice to not run use all your machines' cores as this will make running other programs difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "number_cpu = os.cpu_count()\n",
    "number_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Then we need to setup a dask Client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# setup the dask cluster\n",
    "import dask\n",
    "\n",
    "client = dask.distributed.Client(n_workers=number_cpu-1, threads_per_worker=1)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Clicking on the hyperlink in the output above will bring up the dask client dashboard. The dashboard will display the dask client's progress with running any tasks given to it. The code using `lhs_prcc` below has an additional argument from before, `client` this is the client you wish to use for parallel simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "results_and_sample_df, prccs = lhs_prcc(parameters_df=parameter_samples_df,\n",
    "                                        sample_size=1000,\n",
    "                                        model_run_method=vaccination_lhs_sim,\n",
    "                                        metapop_model=metapop_model,\n",
    "                                        client= client, # this argument tells lhs_prcc to use this dask client.\n",
    "                                        t=t,\n",
    "                                        y0=y,\n",
    "                                        fixed_parameter=other_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "It is best practice to shutdown (`close`) a dask client once you are finished with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "prccs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 5.5 Plotting how Effective Vaccination was given Uncertainties.\n",
    "\n",
    "Lets start by plotting box plots of total hospitalisations and peak hospitalisations from results_and_sample_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(9, 4))\n",
    "for index, result in enumerate(['Total hospitalisations', 'Peak hospitalisations']):\n",
    "    axs[index].violinplot(results_and_sample_df[result],\n",
    "                          showmeans=False,\n",
    "                          showmedians=True)\n",
    "    axs[index].set_title(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Now lets start plot % reductions in total hospitalisations and peak hospitalisations due to vaccination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "hospitalised_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(9, 4))\n",
    "for index, result in enumerate(['Total hospitalisations', 'Peak hospitalisations']):\n",
    "    baseline_value = hospitalised_results_df.loc[hospitalised_results_df['Scenario']=='Starting prevalence of 0.01',result].values[0]\n",
    "    to_plot = (results_and_sample_df[result] - baseline_value)/baseline_value\n",
    "    to_plot *= 100\n",
    "    axs[index].violinplot(to_plot,\n",
    "                          showmeans=False,\n",
    "                          showmedians=True)\n",
    "    axs[index].set_title('% reduction in ' + result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
