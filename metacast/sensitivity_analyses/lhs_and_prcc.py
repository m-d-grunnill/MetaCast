"""
Creation:
    Author: Martin Grunnill
    Date: 2022-10-05
Description: Generate Latin-Hypercube Sample (LHS), run simulations and calculate Partial
Correlation Coefficients (PRCCs). For a description of LHS and PRCCs use in model sensitivity analyses see [1].

Notes
-----
Serial processing of LHS can be slow. but parallel processing of LHS can take up a lot of computing resources.

"""
import pandas as pd
import pingouin as pg
import copy
from scipy.stats import qmc
from tqdm.auto import tqdm
import concurrent

def _format_sample(parameters_df, LH_samples, other_samples_to_repeat=None, include_seed=True):
    """
    Formats Latin Hypercube sample generated by scipy.stats.qmc.

    Scales LH_samples in with boundaries outlined in parameters_df.

    Parameters
    ----------
    parameters_df : pd.DataFrame
        DataFrame outlining the boundaries for each parameter. Must contain fields 'Lower Bound' and
        'Upper Bound'. Name of the parameters is assumed to be in the index.
    LH_samples : numpy.array
        Output from scipy.stats.qmc.LatinHypercube.
    other_samples_to_repeat : pandas.DataFrame
        Samples to resampled and merged with LH samples.
    include_seed : bool
        Is generation of a seed included in Latin Hypercube sampling.

    Returns
    -------
    samples_df : pandas.Dataframe
        Fully formatted samples.
    parameters_sampled : list
        A list of samples being sampled.
    """
    if include_seed:
        parameters_df = copy.deepcopy(parameters_df)
        parameters_df.loc['seed', :] = {'Lower Bound':0, 'Upper Bound':1e9}

    # if any(~parameters_df['Distribution'].isin(['boolean','uniform'])):
    #     raise ValueError('Only Boolean and Uniform distributions currently supported.')
    samples_df = pd.DataFrame(qmc.scale(LH_samples,
                                        parameters_df['Lower Bound'],
                                        parameters_df['Upper Bound']),
                              columns=parameters_df.index)
    if other_samples_to_repeat is not None:
        multiple = len(samples_df)/len(other_samples_to_repeat)
        if not multiple.is_integer():
            raise ValueError('LHS sample size devided by length of other_samples_to_repeat must be expressable as an interger value.')
        multiple = int(multiple)
        repeated_samples = pd.concat([other_samples_to_repeat] * multiple, ignore_index=True)
        samples_df = pd.concat([samples_df, repeated_samples], axis=1, ignore_index=True)
        parameters_sampled = parameters_df.index.to_list() + other_samples_to_repeat.columns.to_list()
        samples_df.columns = parameters_sampled
    else:
        parameters_sampled = samples_df.columns.to_list()

    # convert_to_bool = parameters_df.Parameter[parameters_df['Distribution'] == 'boolean']
    # for parameter in convert_to_bool:
    #     samples_df[parameter] = samples_df[parameter] >= 0.5
    return samples_df, parameters_sampled


def calculate_prcc(results_and_sample_df, parameter, output, covariables, method='spearman'):
    """
    Calculate Partial Correlation Coefficient PCC (default Rank 'Spearman' PRCC).

    A wrapper for pingouin.partial_corr. Partial Rank Correlation Coefficients (PRCCS) can be used to evaluate
    sensitivity of a model to a parameter[1].

    Parameters
    ----------
    results_and_sample_df : pandas.DataFrame
        DataFrame of results and parameters for calculating PCC.
    parameter : string
        Parameter for which PCC will be calculated.
    output : string
        Model output for which PCC will be calculated.
    covariables : list of strings
        Parameters whose effects will be discounted.
    method : string, default 'spearman' (Rank correlations)
        Form of PCC see documentation of pingouin.partial_corr.


    Returns
    -------
    pandas.DataFrame
        Partial Corelation Coefficient of parameter and output.

    References
    ----------
    [1] Marino, S., Hogue, I. B., Ray, C. J., & Kirschner, D. E. (2008). A methodology for performing global uncertainty
        and sensitivity analysis in systems biology. In Journal of Theoretical Biology (Vol. 254, Issue 1, pp. 178–196).
        https://doi.org/10.1016/j.jtbi.2008.04.011
    """
    param_pcor = pg.partial_corr(results_and_sample_df,
                                 x=parameter, y=output,
                                 covar=covariables,
                                 method=method)
    param_pcor.rename(index={method: parameter + ' on ' + output}, inplace=True)
    param_pcor['Number_of_Covariables'] = len(covariables)
    confidence_interval = pd.DataFrame(param_pcor['CI95%'].tolist())
    param_pcor['lower_CI_0.95'] = confidence_interval[0][0]
    param_pcor['upper_CI_0.95'] = confidence_interval[1][0]
    param_pcor.drop(columns=['CI95%'], inplace=True)
    return param_pcor


def lhs_prcc_serial(parameters_df, sample_size, model_run_method,
                    results_csv = None, LHS_obj=None, y0=None, other_samples_to_repeat=None, LHS_include_seed=True):
    """
    Generate a Latin Hypercube sample, run model with sample (serially) and calculate PRCC for sampled parameters.

    Latin Hypercube Sampling with Partial Rank Correlation Coefficients (PRCCS) can be used to evaluate sensitivity of a
    model to a parameter[1].

    Parameters
    ----------
    parameters_df : pandas.DataFrame
        DataFrame outlining the boundaries for each parameter. Must contain fields 'Lower Bound' and
        'Upper Bound'. Name of the parameters is assumed to be in the index.
    sample_size : int
        Sample size of Latin Hypercube.
    model_run_method : function
        Method of running model simulation. Must accept parameters as a single dictionary.
    results_csv : string, optional
        If given results are saved to csv instead of being returned as a dataframe.
    LHS_obj : scipy.stats.qmc.LatinHypercube, optional
        Pre-initialised Latin Hypercube sample generator. If not provided one is generated by the function.
    y0 : numpy.array, optional
        Initial values of starting variables.
    other_samples_to_repeat : pandas.DataFrame
        Samples to resampled and merged with LH samples.
    LHS_include_seed : bool
        Include generation of a seed in Latin Hypercube sampling.

    Returns
    -------
    prccs : pandas.DataFrame
        PRCC summary of the model's sensitivity to its parameters.

    See Also
    --------
    metacast.sensitivity_analyses.lhs_and_prcc_parallel: A parallelized version of this function.

    Notes
    -----
    Serial processing of LHS can be slow. but parallel processing of LHS can take up a lot of computing resources.

    References
    ----------
    [1] Marino, S., Hogue, I. B., Ray, C. J., & Kirschner, D. E. (2008). A methodology for performing global uncertainty
        and sensitivity analysis in systems biology. In Journal of Theoretical Biology (Vol. 254, Issue 1, pp. 178–196).
        https://doi.org/10.1016/j.jtbi.2008.04.011
    """
    if LHS_obj is None:
        num_LH_parameters_sampled = len(parameters_df)
        if LHS_include_seed:
            num_LH_parameters_sampled += 1
        LHS_obj = qmc.LatinHypercube(num_LH_parameters_sampled)
    LH_sample = LHS_obj.random(sample_size)
    sample_df, parameters_sampled = _format_sample(parameters_df, LH_sample, other_samples_to_repeat,
                                                   include_seed=LHS_include_seed)
    focused_results_and_sample_records = []
    samples = sample_df.to_dict('records')
    for sample in tqdm(samples, desc='Simulating LH Sample', position=1, leave=False, colour='green'):
        if y0 is None:
            focused_results_and_sample_records.append(model_run_method(sample))
        else:
            focused_results_and_sample_records.append(model_run_method(sample, y0=y0))
    focused_results_and_sample_df = pd.DataFrame.from_records(focused_results_and_sample_records)
    prccs = []
    for parameter in parameters_sampled:
        covariables = [item
                       for item in parameters_sampled
                       if item != parameter]
        for column in focused_results_and_sample_df.columns:
            if column not in parameters_sampled:
                param_rank_pcor = calculate_prcc(sample_df, parameter, column, covariables, method='spearman')
                prccs.append(param_rank_pcor)

    prccs = pd.concat(prccs)
    prccs.sort_index(inplace=True)
    if results_csv is not None:
        prccs.to_csv(results_csv)
    else:
        return prccs

def run_samples_in_parallel(sample_df, model_run_method, max_workers=None, return_focused_results=True, **kwargs):
    """
    Runs model simulations using parameters in sample_df using parallel processing.

    Parameters
    ----------
    sample_df : pandas.Dataframe
        Parameter samples being run. Column fields are parameters.
    model_run_method : function
        Method of running model simulation. Must accept parameters as a single dictionary.
    max_workers : int, optional defaults to maximum available.
        Number of workers/cpu/cores used in running simulations.
    return_focused_results : bool, default True
        Return results as dataframe.
    kwargs : dictionary
        Key word arguments to pass to model_run_method.

    Returns
    -------
    If return_focused_results is True a pandas DataFrame of results is returned.
    """
    samples = sample_df.to_dict('records')
    with tqdm(total=len(sample_df),
              desc='Simulating LH Sample',
              position=1,
              leave=False,
              colour='green') as pbar: # add a progress bar.
        with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor: # set up paralisation for simulations
            simlations = [executor.submit(model_run_method, sample, **kwargs) for sample in samples]
            focused_results_and_sample_records = []
            for simlation in concurrent.futures.as_completed(simlations):
                focused_results_and_sample_records.append(simlation.result())
                pbar.update(1)
    if return_focused_results:
        focused_results_and_sample_df = pd.DataFrame.from_records(focused_results_and_sample_records)
        return focused_results_and_sample_df


def lhs_and_prcc_parallel(parameters_df,
                          sample_size,
                          model_run_method,
                          results_csv = None,
                          LHS_obj=None,
                          other_samples_to_repeat=None,
                          max_workers=None,
                          LHS_include_seed=True):
    """
    Generate a Latin Hypercube sample, run model with sample (in parallel) and calculate PRCC for sampled parameters.

    Latin Hypercube Sampling with Partial Rank Correlation Coefficients (PRCCS) can be used to evaluate sensitivity of a
    model to a parameter[1].

    Parameters
    ----------
    parameters_df : pd.DataFrame
        DataFrame outlining the boundaries for each parameter. Must contain fields 'Lower Bound' and
        'Upper Bound'. Name of the parameters is assumed to be in the index.
    sample_size : int
        Sample size of Latin Hypercube.
    model_run_method : function
        Method of running model simulation. Must accept parameters as a single dictionary.
    results_csv : string, optional
        If given results are saved to csv instead of being returned as a dataframe.
    LHS_obj : scipy.stats.qmc.LatinHypercube, optional
        Pre-initialised Latin Hypercube sample generator. If not provided one is generated by the function.
    other_samples_to_repeat :
    max_workers : int, optional defaults to maximum available.
        Number of workers/cpu/cores used in running simulations
    LHS_include_seed : bool
        Include generation of a seed in Latin Hypercube sampling.

    Returns
    -------
    prccs : pandas.DataFrame
        PRCC summary of the model's sensitivity to its parameters.

    See Also
    --------
    metacast.sensitivity_analyses.lhs_and_prcc_serial: A serial version of this function.

    Notes
    -----
    Serial processing of LHS can be slow. but parallel processing of LHS can take up a lot of computing resources.

    References
    ----------
    [1] Marino, S., Hogue, I. B., Ray, C. J., & Kirschner, D. E. (2008). A methodology for performing global uncertainty
        and sensitivity analysis in systems biology. In Journal of Theoretical Biology (Vol. 254, Issue 1, pp. 178–196).
        https://doi.org/10.1016/j.jtbi.2008.04.011

    """
    # Future improvement: a lot of this is repeated from the serial version (lhs_prcc_serial).
    # Maybe worth moving repeated sections to private methods or merging the two function into one (switch from paralell
    # to serial through optional arguments).
    if LHS_obj is None:
        num_LH_parameters_sampled = len(parameters_df)
        if LHS_include_seed:
            num_LH_parameters_sampled += 1
        LHS_obj = qmc.LatinHypercube(num_LH_parameters_sampled)
    LH_sample = LHS_obj.random(sample_size)
    sample_df, parameters_sampled = _format_sample(parameters_df, LH_sample, other_samples_to_repeat,
                                                   include_seed=LHS_include_seed)
    focused_results_and_sample_df = run_samples_in_parallel(sample_df, model_run_method, max_workers=max_workers)
    prccs = []
    for parameter in parameters_sampled:
        covariables = [item
                       for item in parameters_sampled
                       if item != parameter]
        for column in focused_results_and_sample_df.columns:
            if column not in parameters_sampled:
                param_rank_pcor = calculate_prcc(focused_results_and_sample_df, parameter, column, covariables,
                                                 method='spearman')
                prccs.append(param_rank_pcor)

    prccs = pd.concat(prccs)
    prccs.sort_index(inplace=True)
    if results_csv is not None:
        prccs.to_csv(results_csv)
    else:
        return prccs

