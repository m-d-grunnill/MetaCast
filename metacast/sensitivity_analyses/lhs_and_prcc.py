"""
Creation:
    Author: Martin Grunnill
    Date: 2022-10-05
Description: Generate Latin-Hypercube Sample (LHS), run simulations and calculate Partial
Correlation Coefficients (PRCCs). For a description of LHS and PRCCs use in model sensitivity analyses see [1].

Notes
-----
Serial processing of LHS can be slow. but parallel processing of LHS can take up a lot of computing resources.

"""
import pandas as pd
import pingouin as pg
import copy
from scipy.stats import qmc
from tqdm.auto import tqdm
import concurrent

def _format_sample(parameters_df, LH_samples, other_samples_to_repeat=None):
    """
    Formats Latin Hypercube sample generated by scipy.stats.qmc.

    Scales LH_samples in with boundaries outlined in parameters_df.

    Parameters
    ----------
    parameters_df : pd.DataFrame
        DataFrame outlining the boundaries for each parameter. Must contain fields 'Lower Bound' and
        'Upper Bound'. Name of the parameters is assumed to be in the index.
    LH_samples : numpy.array
        Output from scipy.stats.qmc.LatinHypercube.
    other_samples_to_repeat : pandas.DataFrame
        Samples to resampled and merged with LH samples.

    Returns
    -------
    samples_df : pandas.Dataframe
        Fully formatted samples.
    parameters_sampled : list
        A list of samples being sampled.
    """
    # if any(~parameters_df['Distribution'].isin(['boolean','uniform'])):
    #     raise ValueError('Only Boolean and Uniform distributions currently supported.')
    samples_df = pd.DataFrame(qmc.scale(LH_samples,
                                        parameters_df['Lower Bound'],
                                        parameters_df['Upper Bound']),
                              columns=parameters_df.index)
    if other_samples_to_repeat is not None:
        multiple = len(samples_df)/len(other_samples_to_repeat)
        if not multiple.is_integer():
            raise ValueError('LHS sample size devided by length of other_samples_to_repeat must be expressable as an interger value.')
        multiple = int(multiple)
        repeated_samples = pd.concat([other_samples_to_repeat] * multiple, ignore_index=True)
        samples_df = pd.concat([samples_df, repeated_samples], axis=1, ignore_index=True)
        parameters_sampled = parameters_df.index.to_list() + other_samples_to_repeat.columns.to_list()
        samples_df.columns = parameters_sampled
    else:
        parameters_sampled = samples_df.columns.to_list()

    # convert_to_bool = parameters_df.Parameter[parameters_df['Distribution'] == 'boolean']
    # for parameter in convert_to_bool:
    #     samples_df[parameter] = samples_df[parameter] >= 0.5
    return samples_df, parameters_sampled


def calculate_prcc(results_and_sample_df, parameter, output, covariables, method='spearman'):
    """
    Calculate Partial Correlation Coefficient PCC (default Rank 'Spearman' PRCC).

    A wrapper for pingouin.partial_corr. Partial Rank Correlation Coefficients (PRCCS) can be used to evaluate
    sensitivity of a model to a parameter[1].

    Parameters
    ----------
    results_and_sample_df : pandas.DataFrame
        DataFrame of results and parameters for calculating PCC.
    parameter : string
        Parameter for which PCC will be calculated.
    output : string
        Model output for which PCC will be calculated.
    covariables : list of strings
        Parameters whose effects will be discounted.
    method : string, default 'spearman' (Rank correlations)
        Form of PCC see documentation of pingouin.partial_corr.


    Returns
    -------
    pandas.DataFrame
        Partial Corelation Coefficient of parameter and output.

    References
    ----------
    [1] Marino, S., Hogue, I. B., Ray, C. J., & Kirschner, D. E. (2008). A methodology for performing global uncertainty
        and sensitivity analysis in systems biology. In Journal of Theoretical Biology (Vol. 254, Issue 1, pp. 178–196).
        https://doi.org/10.1016/j.jtbi.2008.04.011
    """
    param_pcor = pg.partial_corr(results_and_sample_df,
                                 x=parameter, y=output,
                                 covar=covariables,
                                 method=method)
    param_pcor.rename(index={method: parameter + ' on ' + output}, inplace=True)
    param_pcor['Number_of_Covariables'] = len(covariables)
    confidence_interval = pd.DataFrame(param_pcor['CI95%'].tolist())
    param_pcor['lower_CI_0.95'] = confidence_interval[0][0]
    param_pcor['upper_CI_0.95'] = confidence_interval[1][0]
    param_pcor.drop(columns=['CI95%'], inplace=True)
    return param_pcor


def lhs_prcc(parameters_df, sample_size, model_run_method, max_workers = None, LHS_obj=None, other_samples_to_repeat=None):
    """
    Generate a Latin Hypercube sample, run model with sample (serially) and calculate PRCC for sampled parameters.

    Latin Hypercube Sampling with Partial Rank Correlation Coefficients (PRCCS) can be used to evaluate sensitivity of a
    model to a parameter[1]. Note currently only supports uniform distribution.

    Parameters
    ----------
    parameters_df : pandas.DataFrame
        DataFrame outlining the boundaries for each parameter. Must contain fields 'Lower Bound' and
        'Upper Bound'. Name of the parameters is assumed to be in the index.
    sample_size : int
        Sample size of Latin Hypercube.
    model_run_method : function
        Method of running model simulations. Must accept parameters as a single dictionary.
    LHS_obj : scipy.stats.qmc.LatinHypercube, optional
        Pre-initialised Latin Hypercube sample generator. If not provided one is generated by the function.
    other_samples_to_repeat : pandas.DataFrame
        Samples to resampled and merged with LH samples.

    Returns
    -------
    prccs : pandas.DataFrame
        PRCC summary of the model's sensitivity to its parameters.

    See Also
    --------
    metacast.sensitivity_analyses.lhs_and_prcc_parallel: A parallelized version of this function.

    Notes
    -----
    Serial processing of LHS can be slow. but parallel processing of LHS can take up a lot of computing resources.

    References
    ----------
    [1] Marino, S., Hogue, I. B., Ray, C. J., & Kirschner, D. E. (2008). A methodology for performing global uncertainty
        and sensitivity analysis in systems biology. In Journal of Theoretical Biology (Vol. 254, Issue 1, pp. 178–196).
        https://doi.org/10.1016/j.jtbi.2008.04.011
    """
    if LHS_obj is None:
        num_LH_parameters_sampled = len(parameters_df)
        LHS_obj = qmc.LatinHypercube(num_LH_parameters_sampled)
    LH_sample = LHS_obj.random(sample_size)
    sample_df, parameters_sampled = _format_sample(parameters_df, LH_sample, other_samples_to_repeat)
    if max_workers == 1:
        results = run_samples_serially(sample_df, model_run_method)
    else:
        results = run_samples_in_parallel(sample_df, model_run_method, max_workers=max_workers)


    results_df = pd.DataFrame.from_records(results)
    result_columns = [column
                      for column in list(results_df.columns)
                      if column not in parameters_sampled]
    results_df = results_df[parameters_sampled + result_columns]

    prccs = []
    for parameter in parameters_sampled:
        covariables = [item
                       for item in parameters_sampled
                       if item != parameter]
        for column in result_columns:
            param_rank_pcor = calculate_prcc(sample_df, parameter, column, covariables, method='spearman')
            prccs.append(param_rank_pcor)

    prccs = pd.concat(prccs)
    prccs.sort_index(inplace=True)
    return results_df, prccs


def run_samples_serially(sample_df, model_run_method):
    samples = sample_df.to_dict('records')
    results = []
    for sample in tqdm(samples, desc='Simulating LH Sample', position=1, leave=False, colour='green'):
        results.append(model_run_method(sample))
    return results

def run_samples_in_parallel(sample_df, model_run_method,
                            max_workers=None):
    """
    Runs model simulations using parameters in sample_df using parallel processing.

    Parameters
    ----------
    sample_df : pandas.Dataframe
        Parameter samples being run. Column fields are parameters.
    model_run_method : function
        Method of running model simulations. Must accept parameters as a single dictionary.
    max_workers : int, optional defaults to maximum available.
        Number of workers/cpu/cores used in running simulations.

    Returns
    -------
    If return_focused_results is True a pandas DataFrame of results is returned.
    """
    samples = sample_df.to_dict('records')
    with tqdm(total=len(sample_df),
              desc='Simulating LH Sample',
              position=1,
              leave=False,
              colour='green') as pbar: # add a progress bar.
        with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor: # set up paralisation for simulations
            simlations = [executor.submit(model_run_method, sample) for sample in samples]
            results = []
            for simlation in concurrent.futures.as_completed(simlations):
                results.append(simlation.result())
                pbar.update(1)

    return results


